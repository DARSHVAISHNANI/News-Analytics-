{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9fbd61-446d-44bb-9d58-70d1007c0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c9be5e-d92f-40fc-8b92-b1681b5ae2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.moneycontrol.com/news/india/puja-khedkar-wont-be-arrested-till-september-5-12809495.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5932263-dc02-4fa2-a7cb-3d863999d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Delhi High Court on Thursday extended interim protection from arrest to former probationary IAS officer Puja Khedkar till September 5. A case was registered against her for fraudulently availing attempts in the Union Public Service Commission (UPSC) examination beyond the permissible limit by faking her identity.\n",
      "Earlier, during a hearing on Khedkar’s anticipatory bail plea, Justice Subramonium Prasad of the Delhi High Court deferred the hearing to August 29, 2024, as the Delhi Police had not filed its response.\n",
      "Senior advocate Siddharth Luthra, representing Khedkar, requested additional time to review the UPSC’s response, which opposes the anticipatory bail plea.\n",
      "At the previous hearing, the Delhi High Court had issued notices to both the Delhi Police and the UPSC regarding Khedkar’s bail plea.\n",
      "The Delhi High Court had earlier observed that the trial court’s order denying bail to Khedkar lacked substantial discussion, with only a brief mention of the public prosecutor’s claims about the involvement of others. The High Court had instructed the police not to arrest Khedkar while the proceedings were ongoing.\n",
      "The UPSC had, on August 21, opposed Khedkar’s anticipatory bail plea, arguing that her custodial interrogation is essential to \"unearth\" the truth about those who assisted her in fraudulently securing additional civil services examination attempts by falsifying her identity.\n",
      "In an affidavit submitted before the Delhi High Court, the Commission had highlighted the seriousness of the fraud, which it claimed has compromised not only the UPSC's reputation but also public trust in its credibility.\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "link_segment = link.split(\"/\")[-1]\n",
    "\n",
    "# Take the first two words from the last segment of the link\n",
    "file_name_prefix = \"-\".join(link_segment.split('-')[:2])\n",
    "\n",
    "# Create a timestamp for the filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Automatically name the JSON file with the link segment and timestamp\n",
    "json_filename = f\"MC_News_{file_name_prefix}_{timestamp}.json\"\n",
    "json_filepath = f\"C:\\\\Users\\\\darsh\\\\Desktop\\\\Main Documents Folder\\\\ADANI-MSBC HACKATHON\\\\Money Control Extraction\\\\{json_filename}\"\n",
    "\n",
    "# List to store extracted paragraphs\n",
    "filtered_sentences = []\n",
    "\n",
    "# Create a request object to handle the webpage\n",
    "req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(webpage, 'html5lib')\n",
    "\n",
    "# Find the relevant sections containing news items\n",
    "for item in soup.find_all('div', attrs={'class': 'content_wrapper arti-flow'}):\n",
    "    for para in item.find_all('p'):\n",
    "        para_sentences = para.get_text()\n",
    "        print(para_sentences)\n",
    "        # Check if the sentence has 20 or more words\n",
    "        if len(para_sentences.split()) >= 20:\n",
    "            filtered_sentences.append({\"text\": para_sentences})\n",
    "\n",
    "# # Write the filtered sentences to the JSON file\n",
    "# with open(json_filepath, 'w') as outfile:\n",
    "#     json.dump(filtered_sentences, outfile, indent=4)\n",
    "\n",
    "# # Print or confirm success\n",
    "# print(f\"Sentences have been saved to {json_filepath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4908aeb0-d153-4654-8d78-1d293654ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article has been saved to C:\\Users\\darsh\\Desktop\\Main Documents Folder\\ADANI-MSBC HACKATHON\\Money Control Extraction\\MC_News_puja-khedkar_20240831_115246.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming 'link' is already defined\n",
    "link_segment = link.split(\"/\")[-1]\n",
    "\n",
    "# Take the first two words from the last segment of the link\n",
    "file_name_prefix = \"-\".join(link_segment.split('-')[:2])\n",
    "\n",
    "# Create a timestamp for the filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Automatically name the JSON file with the link segment and timestamp\n",
    "json_filename = f\"MC_News_{file_name_prefix}_{timestamp}.json\"\n",
    "json_filepath = f\"C:\\\\Users\\\\darsh\\\\Desktop\\\\Main Documents Folder\\\\ADANI-MSBC HACKATHON\\\\Money Control Extraction\\\\{json_filename}\"\n",
    "\n",
    "# Create a request object to handle the webpage\n",
    "req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(webpage, 'html5lib')\n",
    "\n",
    "# Initialize an empty string for the combined article\n",
    "combined_article = \"\"\n",
    "\n",
    "# Find the relevant sections containing news items\n",
    "for item in soup.find_all('div', attrs={'class': 'content_wrapper arti-flow'}):\n",
    "    for para in item.find_all('p'):\n",
    "        para_sentences = para.get_text()\n",
    "        # Append the paragraph text to the combined_article\n",
    "        combined_article += para_sentences + \"\\n\"\n",
    "\n",
    "# Store the combined article in a dictionary\n",
    "article_data = {\"article\": combined_article}\n",
    "\n",
    "# Write the article data to the JSON file\n",
    "with open(json_filepath, 'w') as outfile:\n",
    "    json.dump(article_data, outfile, indent=4)\n",
    "\n",
    "# Print or confirm success\n",
    "print(f\"Article has been saved to {json_filepath}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1f95f-be33-4da2-b233-2db002db8cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
